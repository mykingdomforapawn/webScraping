# webScraping
> This was one of the first projects I implemented. Therefore, it is far from perfect. 
> If you have any suggestions concerning the programming style, implementation, documentation, etc. please let me know.

## Table of contents:
- [What is it?](#what-is-it)
- [Why did I do it?](#why-did-i-do-it)
- [How to use it?](#how-to-use-it)
- [Would I do it again?](#would-i-do-it-again)

---

## What is it?
This is a web scraper designed to accumulate geographical, financial and social data about all sovereign countries from Wikipedia. This process follows two steps. First, a list of all countries and the links to their Wikipedia page is downloaded. Second, each Wikipedia page is visited individually to scrape previously defined features of a country. The data is used to create a geography quiz based on Anki flashcards.


## Why did I do it?
**The big picture:** To have an idea abouts what's going on in the world, it is absolutely necessary to know and compare geographical, financial and social facts about countries. Many conflicts, political movements and social changes can be explained with these numbers and maps.

**Information literacy:** I tried a few geography apps but the data was incomplete or too detailed. This project allows me to decide which information to learn.

**Programming skills:** Learning and applying programming skills was a part of my studies, but writing a few lines for an assignment with a predefined result and conceptualising/implementing a whole project by yourself are two completly different things.


## How to use it?
1. Getting started: requirements.txt
2. Defining the features: .py file
3. Running the script: - feature_list.csv
4: The data: - data.csv
5. From data to flashcards:- anki and import and link to repo mit cards

## Would I do it again
for sure, is spend too much time with courses etc. it was time for a project.
